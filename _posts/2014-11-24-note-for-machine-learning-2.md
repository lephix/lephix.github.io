---
layout: post
title: 机器学习实战笔记
includeMathJax: true
---

## k-近邻算法 kNN
k-近邻算法(kNN)采用测量不同特征值之间的距离方法进行分类。

优点：精度高，对异常值不敏感，无数据输入假定  
缺点：计算复杂度和空间复杂度都较高  
适用数据范围：数值型和标称型

## 决策树
决策树的关键在于建立决策树。  
利用ID3方法构建决策树：通过分别计算将数据按照每种特征进行划分后的信息增益，得到最佳划分特征，并递归获得决策树。

香农熵：  
对于任意一个随机变量X，它的熵定义如下：变量的不确定性越大，熵也就越大，把它搞清楚所需要的信息量也就越大。  
<div>
`H(x) = - sum_x P(x) log_2P(x)`
</div>

信息增益：  
将数据划分之前的熵和信息划分之后的熵相减及为信息增益。

优点：计算复杂度不高，输出结果容易理解，对中间值的缺失不敏感，可以处理不相关特征数据  
缺点：可能产生过度匹配的问题
适用范围：数值型和标称型

